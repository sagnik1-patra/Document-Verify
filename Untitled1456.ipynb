{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9be022f9-c0c3-4c4b-8743-5ed6e26eaf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Data root: C:\\Users\\sagni\\Downloads\\Docu Verify\\Forged Handwritten Document Database\\Forged Handwritten Document Database\\Handwritten Forged Document Dataset 2023\n",
      "[INFO] Classes: ['Blur', 'Copy Paste', 'CopyPaste+Blur', 'CopyPaste+Insertion', 'CopyPaste+Noise', 'Insertion', 'Insertion+Blur', 'Insertion+Noise', 'Noise', 'Normal']\n",
      "Found 400 images belonging to 10 classes.\n",
      "Found 100 images belonging to 10 classes.\n",
      "[INFO] Class indices: {'Blur': 0, 'Copy Paste': 1, 'CopyPaste+Blur': 2, 'CopyPaste+Insertion': 3, 'CopyPaste+Noise': 4, 'Insertion': 5, 'Insertion+Blur': 6, 'Insertion+Noise': 7, 'Noise': 8, 'Normal': 9}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,810</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │       \u001b[38;5;34m4,049,571\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │          \u001b[38;5;34m12,810\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,062,381</span> (15.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,062,381\u001b[0m (15.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,810</span> (50.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,810\u001b[0m (50.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593ms/step - accuracy: 0.1073 - loss: 2.3699\n",
      "Epoch 1: val_accuracy improved from -inf to 0.10000, saving model to C:\\Users\\sagni\\Downloads\\Docu Verify\\model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 912ms/step - accuracy: 0.1067 - loss: 2.3714 - val_accuracy: 0.1000 - val_loss: 2.3524 - learning_rate: 0.0010\n",
      "Epoch 2/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573ms/step - accuracy: 0.1034 - loss: 2.3682\n",
      "Epoch 2: val_accuracy improved from 0.10000 to 0.11000, saving model to C:\\Users\\sagni\\Downloads\\Docu Verify\\model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 691ms/step - accuracy: 0.1036 - loss: 2.3683 - val_accuracy: 0.1100 - val_loss: 2.3473 - learning_rate: 0.0010\n",
      "Epoch 3/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593ms/step - accuracy: 0.0906 - loss: 2.3625\n",
      "Epoch 3: val_accuracy did not improve from 0.11000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 696ms/step - accuracy: 0.0904 - loss: 2.3633 - val_accuracy: 0.1000 - val_loss: 2.3378 - learning_rate: 0.0010\n",
      "Epoch 4/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583ms/step - accuracy: 0.0888 - loss: 2.3627\n",
      "Epoch 4: val_accuracy did not improve from 0.11000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 688ms/step - accuracy: 0.0888 - loss: 2.3626 - val_accuracy: 0.1000 - val_loss: 2.3156 - learning_rate: 0.0010\n",
      "Epoch 5/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556ms/step - accuracy: 0.1165 - loss: 2.3457\n",
      "Epoch 5: val_accuracy did not improve from 0.11000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 661ms/step - accuracy: 0.1160 - loss: 2.3468 - val_accuracy: 0.1100 - val_loss: 2.3247 - learning_rate: 0.0010\n",
      "Epoch 6/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549ms/step - accuracy: 0.1115 - loss: 2.3095\n",
      "Epoch 6: val_accuracy did not improve from 0.11000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 654ms/step - accuracy: 0.1107 - loss: 2.3110 - val_accuracy: 0.1000 - val_loss: 2.3145 - learning_rate: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved model: C:\\Users\\sagni\\Downloads\\Docu Verify\\model.h5\n",
      "[INFO] Saved class map: C:\\Users\\sagni\\Downloads\\Docu Verify\\class_indices.pkl\n",
      "[INFO] Saved metrics: C:\\Users\\sagni\\Downloads\\Docu Verify\\metrics.json\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 804ms/step\n",
      "[INFO] Saved val predictions: C:\\Users\\sagni\\Downloads\\Docu Verify\\val_predictions.json\n",
      "[INFO] Saved accuracy/loss plots: C:\\Users\\sagni\\Downloads\\Docu Verify\\accuracy_loss.png (+ separate acc/loss PNGs)\n",
      "[INFO] Saved classification report CSV: C:\\Users\\sagni\\Downloads\\Docu Verify\\classification_report.csv\n",
      "[INFO] Saved confusion matrix CSV: C:\\Users\\sagni\\Downloads\\Docu Verify\\confusion_matrix.csv\n",
      "[INFO] Saved confusion matrix heatmap: C:\\Users\\sagni\\Downloads\\Docu Verify\\confusion_matrix.png\n",
      "[INFO] Saved run config: C:\\Users\\sagni\\Downloads\\Docu Verify\\run_config.yaml\n",
      "\n",
      "[DONE] All artifacts saved to: C:\\Users\\sagni\\Downloads\\Docu Verify\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import pickle\n",
    "import random\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# ----------------------------------\n",
    "# CONFIG (Windows raw-string paths)\n",
    "# ----------------------------------\n",
    "DATA_DIRS: List[str] = [\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Docu Verify\\Forged Handwritten Document Database\\Forged Handwritten Document Database\\Handwritten Forged Document Dataset 2023\\Normal\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Docu Verify\\Forged Handwritten Document Database\\Forged Handwritten Document Database\\Handwritten Forged Document Dataset 2023\\Insertion+Blur\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Docu Verify\\Forged Handwritten Document Database\\Forged Handwritten Document Database\\Handwritten Forged Document Dataset 2023\\Insertion+Noise\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Docu Verify\\Forged Handwritten Document Database\\Forged Handwritten Document Database\\Handwritten Forged Document Dataset 2023\\Noise\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Docu Verify\\Forged Handwritten Document Database\\Forged Handwritten Document Database\\Handwritten Forged Document Dataset 2023\\CopyPaste+Insertion\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Docu Verify\\Forged Handwritten Document Database\\Forged Handwritten Document Database\\Handwritten Forged Document Dataset 2023\\CopyPaste+Noise\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Docu Verify\\Forged Handwritten Document Database\\Forged Handwritten Document Database\\Handwritten Forged Document Dataset 2023\\Insertion\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Docu Verify\\Forged Handwritten Document Database\\Forged Handwritten Document Database\\Handwritten Forged Document Dataset 2023\\Copy Paste\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Docu Verify\\Forged Handwritten Document Database\\Forged Handwritten Document Database\\Handwritten Forged Document Dataset 2023\\CopyPaste+Blur\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Docu Verify\\Forged Handwritten Document Database\\Forged Handwritten Document Database\\Handwritten Forged Document Dataset 2023\\Blur\",\n",
    "]\n",
    "# Parent directory for flow_from_directory:\n",
    "DATA_ROOT = str(Path(DATA_DIRS[0]).parent)\n",
    "\n",
    "OUTPUT_DIR = r\"C:\\Users\\sagni\\Downloads\\Docu Verify\"\n",
    "# Core artifacts\n",
    "MODEL_H5       = str(Path(OUTPUT_DIR) / \"model.h5\")\n",
    "CLASS_PKL      = str(Path(OUTPUT_DIR) / \"class_indices.pkl\")\n",
    "RUN_YAML       = str(Path(OUTPUT_DIR) / \"run_config.yaml\")\n",
    "METRICS_JSON   = str(Path(OUTPUT_DIR) / \"metrics.json\")\n",
    "VAL_PRED_JSON  = str(Path(OUTPUT_DIR) / \"val_predictions.json\")\n",
    "# Plot/report artifacts\n",
    "ACC_COMBINED_PNG = str(Path(OUTPUT_DIR) / \"accuracy_loss.png\")\n",
    "ACC_ONLY_PNG     = str(Path(OUTPUT_DIR) / \"accuracy_loss_acc.png\")\n",
    "LOSS_ONLY_PNG    = str(Path(OUTPUT_DIR) / \"accuracy_loss_loss.png\")\n",
    "CM_PNG           = str(Path(OUTPUT_DIR) / \"confusion_matrix.png\")\n",
    "CR_CSV           = str(Path(OUTPUT_DIR) / \"classification_report.csv\")\n",
    "CM_CSV           = str(Path(OUTPUT_DIR) / \"confusion_matrix.csv\")\n",
    "\n",
    "# Model / training params\n",
    "IMG_SIZE   = (256, 256)   # a bit larger than 224 suits documents\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS     = 15\n",
    "VAL_SPLIT  = 0.2\n",
    "SEED       = 42\n",
    "LR         = 1e-3\n",
    "AUGMENT    = True\n",
    "\n",
    "# ----------------------------------\n",
    "# Reproducibility\n",
    "# ----------------------------------\n",
    "def set_seed(s=SEED):\n",
    "    random.seed(s); np.random.seed(s); tf.random.set_seed(s)\n",
    "set_seed()\n",
    "\n",
    "# ----------------------------------\n",
    "# Prep & sanity checks\n",
    "# ----------------------------------\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "if not Path(DATA_ROOT).exists():\n",
    "    raise FileNotFoundError(f\"DATA_ROOT not found: {DATA_ROOT}\")\n",
    "for p in DATA_DIRS:\n",
    "    if not Path(p).exists():\n",
    "        raise FileNotFoundError(f\"Class folder missing: {p}\")\n",
    "\n",
    "expected_classes = sorted([Path(p).name for p in DATA_DIRS])\n",
    "print(\"[INFO] Data root:\", DATA_ROOT)\n",
    "print(\"[INFO] Classes:\", expected_classes)\n",
    "\n",
    "# ----------------------------------\n",
    "# Data pipeline\n",
    "# ----------------------------------\n",
    "if AUGMENT:\n",
    "    train_gen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input,\n",
    "        validation_split=VAL_SPLIT,\n",
    "        rotation_range=3,\n",
    "        width_shift_range=0.03,\n",
    "        height_shift_range=0.03,\n",
    "        zoom_range=0.05,\n",
    "        brightness_range=(0.9, 1.1),\n",
    "        fill_mode=\"nearest\",\n",
    "    )\n",
    "else:\n",
    "    train_gen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input,\n",
    "        validation_split=VAL_SPLIT,\n",
    "    )\n",
    "\n",
    "val_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=VAL_SPLIT\n",
    ")\n",
    "\n",
    "train_flow = train_gen.flow_from_directory(\n",
    "    DATA_ROOT,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    classes=expected_classes,        # explicit class order\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    subset=\"training\",\n",
    "    seed=SEED\n",
    ")\n",
    "val_flow = val_gen.flow_from_directory(\n",
    "    DATA_ROOT,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    classes=expected_classes,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,                   # IMPORTANT for confusion matrix\n",
    "    subset=\"validation\",\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "num_classes = len(train_flow.class_indices)\n",
    "print(\"[INFO] Class indices:\", train_flow.class_indices)\n",
    "\n",
    "# ----------------------------------\n",
    "# Model (EfficientNetB0)\n",
    "# ----------------------------------\n",
    "device = \"/GPU:0\" if tf.config.list_physical_devices(\"GPU\") else \"/CPU:0\"\n",
    "with tf.device(device):\n",
    "    base = EfficientNetB0(include_top=False, input_shape=(*IMG_SIZE, 3), weights=\"imagenet\")\n",
    "    base.trainable = False  # freeze for initial training\n",
    "\n",
    "    inputs = layers.Input(shape=(*IMG_SIZE, 3))\n",
    "    x = base(inputs, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(LR),\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "\n",
    "# ----------------------------------\n",
    "# Callbacks\n",
    "# ----------------------------------\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_accuracy\", patience=4, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-6, verbose=1),\n",
    "    ModelCheckpoint(MODEL_H5, monitor=\"val_accuracy\", save_best_only=True, verbose=1),\n",
    "]\n",
    "\n",
    "# ----------------------------------\n",
    "# Train\n",
    "# ----------------------------------\n",
    "history = model.fit(\n",
    "    train_flow,\n",
    "    validation_data=val_flow,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Ensure the best model is saved; also save current\n",
    "model.save(MODEL_H5)\n",
    "print(f\"[INFO] Saved model: {MODEL_H5}\")\n",
    "\n",
    "# ----------------------------------\n",
    "# Save class indices (PKL)\n",
    "# ----------------------------------\n",
    "with open(CLASS_PKL, \"wb\") as f:\n",
    "    pickle.dump(train_flow.class_indices, f)\n",
    "print(f\"[INFO] Saved class map: {CLASS_PKL}\")\n",
    "\n",
    "# ----------------------------------\n",
    "# Save metrics (JSON)\n",
    "# ----------------------------------\n",
    "metrics_payload = {\n",
    "    \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "    \"device\": device,\n",
    "    \"epochs_run\": len(history.history[\"loss\"]),\n",
    "    \"final\": {\n",
    "        \"train_accuracy\": float(history.history[\"accuracy\"][-1]),\n",
    "        \"train_loss\": float(history.history[\"loss\"][-1]),\n",
    "        \"val_accuracy\": float(history.history[\"val_accuracy\"][-1]),\n",
    "        \"val_loss\": float(history.history[\"val_loss\"][-1]),\n",
    "    },\n",
    "    \"history\": {k: [float(x) for x in v] for k, v in history.history.items()}\n",
    "}\n",
    "with open(METRICS_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metrics_payload, f, indent=2)\n",
    "print(f\"[INFO] Saved metrics: {METRICS_JSON}\")\n",
    "\n",
    "# ----------------------------------\n",
    "# Validation predictions (for CM/report)\n",
    "# ----------------------------------\n",
    "idx_to_class = {v: k for k, v in train_flow.class_indices.items()}\n",
    "\n",
    "val_flow.reset()\n",
    "probs = model.predict(val_flow, verbose=1)  # (N, C)\n",
    "y_pred = np.argmax(probs, axis=1)\n",
    "y_true = val_flow.classes\n",
    "\n",
    "# Save quick JSON with predictions (optional, handy)\n",
    "val_records = []\n",
    "for rel_path, pred_i, conf in zip(val_flow.filenames, y_pred, np.max(probs, axis=1)):\n",
    "    val_records.append({\n",
    "        \"file\": rel_path.replace(\"\\\\\", \"/\"),\n",
    "        \"pred_class\": idx_to_class[int(pred_i)],\n",
    "        \"confidence\": float(conf)\n",
    "    })\n",
    "with open(VAL_PRED_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(val_records, f, indent=2)\n",
    "print(f\"[INFO] Saved val predictions: {VAL_PRED_JSON}\")\n",
    "\n",
    "# ----------------------------------\n",
    "# PLOTS: Accuracy/Loss curves\n",
    "# ----------------------------------\n",
    "# Separate Acc\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train Acc\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Val Acc\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.title(\"Training vs Validation Accuracy\")\n",
    "plt.legend(loc=\"lower right\"); plt.grid(alpha=0.25); plt.tight_layout()\n",
    "plt.savefig(ACC_ONLY_PNG, dpi=200); plt.close()\n",
    "\n",
    "# Separate Loss\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"Training vs Validation Loss\")\n",
    "plt.legend(loc=\"upper right\"); plt.grid(alpha=0.25); plt.tight_layout()\n",
    "plt.savefig(LOSS_ONLY_PNG, dpi=200); plt.close()\n",
    "\n",
    "# Combined\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax1 = fig.add_subplot(2, 1, 1)\n",
    "ax1.plot(history.history[\"accuracy\"], label=\"Train Acc\")\n",
    "ax1.plot(history.history[\"val_accuracy\"], label=\"Val Acc\")\n",
    "ax1.set_xlabel(\"Epoch\"); ax1.set_ylabel(\"Accuracy\"); ax1.set_title(\"Accuracy\")\n",
    "ax1.grid(alpha=0.25); ax1.legend(loc=\"lower right\")\n",
    "\n",
    "ax2 = fig.add_subplot(2, 1, 2)\n",
    "ax2.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "ax2.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
    "ax2.set_xlabel(\"Epoch\"); ax2.set_ylabel(\"Loss\"); ax2.set_title(\"Loss\")\n",
    "ax2.grid(alpha=0.25); ax2.legend(loc=\"upper right\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(ACC_COMBINED_PNG, dpi=200)\n",
    "plt.close(fig)\n",
    "print(f\"[INFO] Saved accuracy/loss plots: {ACC_COMBINED_PNG} (+ separate acc/loss PNGs)\")\n",
    "\n",
    "# ----------------------------------\n",
    "# Confusion Matrix + Classification Report\n",
    "# ----------------------------------\n",
    "labels_order = [idx_to_class[i] for i in range(len(idx_to_class))]\n",
    "cm = confusion_matrix(y_true, y_pred, labels=list(range(len(labels_order))))\n",
    "\n",
    "# Save raw counts matrix\n",
    "pd.DataFrame(cm, index=labels_order, columns=labels_order).to_csv(CM_CSV, index=True)\n",
    "\n",
    "# Save classification report CSV\n",
    "cr_dict = classification_report(y_true, y_pred, target_names=labels_order, output_dict=True, zero_division=0)\n",
    "pd.DataFrame(cr_dict).to_csv(CR_CSV)\n",
    "print(f\"[INFO] Saved classification report CSV: {CR_CSV}\")\n",
    "print(f\"[INFO] Saved confusion matrix CSV: {CM_CSV}\")\n",
    "\n",
    "# Normalized CM for heatmap display\n",
    "cm_norm = cm.astype(\"float\") / cm.sum(axis=1, keepdims=True)\n",
    "cm_norm = np.nan_to_num(cm_norm)\n",
    "\n",
    "# Heatmap with counts + %\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = plt.gca()\n",
    "im = ax.imshow(cm_norm, interpolation=\"nearest\", cmap=\"viridis\")\n",
    "plt.title(\"Confusion Matrix (Normalized)\")\n",
    "cbar = plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "cbar.ax.set_ylabel(\"Proportion\", rotation=90)\n",
    "\n",
    "tick_marks = np.arange(len(labels_order))\n",
    "plt.xticks(tick_marks, labels_order, rotation=45, ha=\"right\")\n",
    "plt.yticks(tick_marks, labels_order)\n",
    "\n",
    "thresh = cm_norm.max() / 2.0\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    count = cm[i, j]\n",
    "    perc  = cm_norm[i, j] * 100.0\n",
    "    txt = f\"{count}\\n{perc:.1f}%\"\n",
    "    ax.text(j, i, txt,\n",
    "            ha=\"center\", va=\"center\",\n",
    "            color=\"white\" if cm_norm[i, j] > thresh else \"black\",\n",
    "            fontsize=9)\n",
    "\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(CM_PNG, dpi=220)\n",
    "plt.close(fig)\n",
    "print(f\"[INFO] Saved confusion matrix heatmap: {CM_PNG}\")\n",
    "\n",
    "# ----------------------------------\n",
    "# Save run config (YAML)\n",
    "# ----------------------------------\n",
    "run_cfg = {\n",
    "    \"run\": {\n",
    "        \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "        \"seed\": SEED,\n",
    "        \"device\": device\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"data_root\": DATA_ROOT,\n",
    "        \"class_dirs\": DATA_DIRS,\n",
    "        \"classes\": expected_classes,\n",
    "        \"val_split\": VAL_SPLIT,\n",
    "        \"image_size\": list(IMG_SIZE),\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"augment\": AUGMENT\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"architecture\": \"EfficientNetB0\",\n",
    "        \"transfer_learning\": True,\n",
    "        \"frozen_base\": True,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"learning_rate\": LR,\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"num_classes\": num_classes\n",
    "    },\n",
    "    \"artifacts\": {\n",
    "        \"model_h5\": MODEL_H5,\n",
    "        \"class_indices_pkl\": CLASS_PKL,\n",
    "        \"metrics_json\": METRICS_JSON,\n",
    "        \"val_predictions_json\": VAL_PRED_JSON,\n",
    "        \"accuracy_loss_png\": ACC_COMBINED_PNG,\n",
    "        \"accuracy_only_png\": ACC_ONLY_PNG,\n",
    "        \"loss_only_png\": LOSS_ONLY_PNG,\n",
    "        \"confusion_matrix_png\": CM_PNG,\n",
    "        \"classification_report_csv\": CR_CSV,\n",
    "        \"confusion_matrix_csv\": CM_CSV\n",
    "    }\n",
    "}\n",
    "with open(RUN_YAML, \"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.safe_dump(run_cfg, f, sort_keys=False, allow_unicode=True)\n",
    "print(f\"[INFO] Saved run config: {RUN_YAML}\")\n",
    "\n",
    "print(\"\\n[DONE] All artifacts saved to:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e43f42-8035-4177-b322-8c56d535abc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
